# Hybrid Multimodal RAG Pipeline

This project implements a modular Retrieval-Augmented Generation (RAG) pipeline that integrates:

- OCR for extracting text from images
- Document routing and chunking
- Hybrid search (keyword + vector)
- Answer generation via Groq (LLaMA 3) with OpenAI fallback
- Multiple execution modes: Manual, LangGraph, and Agentic

---

## ğŸ“Œ Current Status (as of Aug 7, 2025)

### âœ… Implemented & Working
- **OCR + Routing**
  - Primary OCR Agent (`route_document`) with preprocessing
  - Fallback OCR (`fallback_ocr_best`) with multiple PSM modes for accuracy improvement
  - Automatic extraction of company name from invoices
- **Three Pipeline Modes**
  - **Manual Pipeline** â€“ Direct OCR extraction
  - **LangGraph Pipeline** â€“ Orchestrated workflow with OCR + LLM fallback
  - **Agentic Pipeline** â€“ Agent-based reasoning with OCR fallback when LLM confidence is low
- **FastAPI Service**
  - `/healthz` and `/llm-ping` endpoints for health checks
  - `/debug/extract` endpoint to preview document extraction
  - `/eval` endpoint (BM25 + fallback context)
  - `/ask` endpoint (BM25 + TF-IDF + guardrails, with citations)
- **Docker Integration**
  - Application runs in Docker with `docker-compose`
  - Dataset mounted via volume mapping (`./SampleDataSet` â†’ `/app/SampleDataSet`)
- **Error Handling**
  - Graceful handling of missing `.env` or API keys (OpenAI, Grok)
  - Automatic fallback to demo invoice image if file is missing
- **Extended Docker Compose Setup**
  - Add Neo4j, Arize, and any multilingual dependencies as services
- **Neo4j Integration**
  - Export structured entities & relationships
  - Implement `use_neo4j=true` retrieval path in `/ask`

---

### ğŸš§ Pending / Next Steps
- **Retriever Quality Improvements**
  - Enhance BM25 + vector retrieval accuracy for financial PDFs
  - Increase relevant context passed to LLM for better answers
- **Multilingual OCR & Query Support**
  - Language detection and translation for queries/documents
- **Arize Phoenix Observability**
  - Trace RAG pipeline stages, measure LLM latency, and monitor retrieval quality
- **Evaluation Metrics**
  - Implement Token-F1, answer accuracy, and latency reporting
- 


---

## ğŸ— Architecture

```text
[ Document / Image ]
     â†“
[ OCR Agent (primary + fallback) ]
     â†“
[ Document Router ]
     â†“
[ Chunking ]
     â†“
[ Hybrid Retriever (Keyword + Vector) ]
     â†“
[ LLM (Groq / OpenAI) ]
     â†“
[ Final Answer ]


âš™ Setup
1. Clone the repo and create a virtual environment:
bash
Copy
Edit
git clone https://github.com/your-username/raul-hybrid-multimodal-rag.git
cd raul-hybrid-multimodal-rag
python -m venv venv
source venv/bin/activate   # On Windows: venv\Scripts\activate
pip install -r requirements.txt
2. Configure environment variables:
bash
Copy
Edit
cp .env.example .env
Edit .env with your API keys:

env
Copy
Edit
GROQ_API_KEY=your_groq_key_here
OPENAI_API_KEY=your_openai_key_here  # Optional fallback
â–¶ How to Run
Run the main script to execute all pipelines sequentially:

bash
Copy
Edit
python src/main.py
This will:

Manual Pipeline â†’ Runs OCR extraction only

LangGraph Pipeline â†’ Orchestrates RAG with OCR + LLM fallback

Agentic Pipeline â†’ Runs agent-based reasoning with OCR fallback

Sample output:

mathematica
Copy
Edit
 Manual Pipeline â†’ Acme Robotics Inc
 LangGraph Pipeline â†’ Acme Robotics Inc.
 Agentic Pipeline â†’ Acme Robotics Inc.
 Note:

If examples/demo_invoice.png is missing, the script will generate a sample invoice automatically.

You can swap in your own test files in the examples/ directory.

ğŸ§ª Testing
Run all tests with:

bash
Copy
Edit
./test_run.sh
Or manually:

bash
Copy
Edit
python -m pytest -v
ğŸ“‚ File Structure
css
Copy
Edit
src/
  â”œâ”€â”€ agents/
  â”‚   â”œâ”€â”€ agent_controller.py
  â”‚   â””â”€â”€ agent_team.py
  â”œâ”€â”€ graph/
  â”œâ”€â”€ ocr/
  â”‚   â””â”€â”€ ocr_agent.py
  â”œâ”€â”€ retrieval/
  â”‚   â””â”€â”€ hybrid_search.py
  â”œâ”€â”€ router/
  â”‚   â””â”€â”€ doc_router.py
  â””â”€â”€ main.py

examples/
sample_docs/
tests/
.env.example
env
Copy
Edit
# Copy this to `.env` and fill in real keys

GROQ_API_KEY=your_groq_api_key_here
OPENAI_API_KEY=your_openai_api_key_here


curl -s http://localhost:8000/debug/ask-context \
  -H "Content-Type: application/json" \
  --data-binary @req.json | python -m json.tool

Expect: strategy: "probe" and the preview includes â€œTotal net salesâ€.

curl -s http://localhost:8000/ask \
  -H "Content-Type: application/json" \
  --data-binary @req.json | python -m json.tool

Expect: lines like YYYY Q#: $â€¦ and citations in parentheses.

Behavior:
If BM25/TF-IDF canâ€™t confidently select pages or the LLM is unavailable, the API falls back to a heuristic parser that scans 10-Q text for â€œTotal net salesâ€ near â€œThree/Nine Months Endedâ€ and returns quarterly totals with file citations.

Smoke test:

graphql
Copy
Edit
make ctx   # or the curl debug command above
make ask   # should print YYYY Q# totals + citations
Example output:

bash
Copy
Edit
2022 Q3: $82,959 Â· $81,434 Â· $304,182 Â· $282,457
2023 Q1: $117,154 Â· $123,945
2023 Q2: $94,836 Â· $97,278 Â· $211,990 Â· $221,223 (2022 Q3 AAPL.pdf; 2023 Q1 AAPL.pdf; 2023 Q2 AAPL


## ğŸ“¹ Demo Video

Click the image below to watch the demo:

[https://youtu.be/YNVVzHwbBiU]

---

### ğŸ”¹ How to Run Locally

```bash
# 1. Clone the repo
git clone https://github.com/helloraul/raul-hybrid-multimodal-rag/YOUR_REPO.git
cd raul-hybrid-multimodal-rag

# 2. Create virtual environment & install dependencies
python -m venv venv
source venv/bin/activate   # macOS / Linux
venv\Scripts\activate      # Windows

pip install -r requirements.txt

# 3. Start the API server
uvicorn src.main:app --reload

# 4. Test with example request
curl -s http://localhost:8000/ask \
  -H "Content-Type: application/json" \
  --data-binary @req.json | python -m json.tool

